{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "collapsed_sections": [
        "eY8iDCp3BoqV",
        "vnz96AZJBtfA"
      ]
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# ModelPrepare Class to normalize our working ways"
      ],
      "metadata": {
        "id": "dPt25dqUyBvN"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np \n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "from sklearn.model_selection import train_test_split\n",
        "import json\n",
        "from enum import Enum \n",
        "from datetime import datetime\n",
        "from sklearn.metrics import confusion_matrix, plot_confusion_matrix\n",
        "\n",
        "\n",
        "# Enum Class for type checking and forcing\n",
        "class Datasets(Enum):\n",
        "    TRAINING_SET = 'train.csv'\n",
        "    TESTING_SET = 'test.csv'\n",
        "\n",
        "# Class to normalize the way of writing\n",
        "class ModelPrep():\n",
        "  \n",
        "  training_to_testing_map = {\n",
        "      \"age\": 'age',\n",
        "      'work-class': 'workclass',\n",
        "      'work-fnl': 'fnlwgt',\n",
        "      'education': 'education',\n",
        "      'education-num': 'education-num',\n",
        "      'marital-status': 'marital-status',\n",
        "      'position': 'occupation',\n",
        "      'relationship': 'relationship',\n",
        "      'race': 'race',\n",
        "      'sex': 'sex',\n",
        "      'capital-gain': 'capital-gain',\n",
        "      'capital-loss': 'capital-loss',\n",
        "      'hours-per-week': 'hours-per-week',\n",
        "      'native-country': 'native-country'\n",
        "  }\n",
        "\n",
        "  def __init__(self) -> None:\n",
        "    self.columns_properties = {}\n",
        "    self.cache = self.load_cache()\n",
        "    self.training_set = pd.read_csv(Datasets.TRAINING_SET.value) \n",
        "    self.testing_set = pd.read_csv(Datasets.TESTING_SET.value)\n",
        "    self.testing_set.rename(columns = {'occupation':'position'}, inplace = True)\n",
        "    self.testing_set.rename(columns = {'workclass':'work-class'}, inplace = True)\n",
        "\n",
        "  def load_cache(self) -> dict:\n",
        "    try: \n",
        "      with open('model_cache.json', 'r') as file:\n",
        "        return json.load(file) \n",
        "    except:\n",
        "      print(\"No Cache Exists yet\")\n",
        "      return {}\n",
        "  \n",
        "  def __update_cache(self, modelName: str, json_property: dict) -> None:\n",
        "    self.cache[modelName] = json_property\n",
        "    self.__write_cache()\n",
        "  \n",
        "  def __write_cache(self) -> None:\n",
        "    with open('model_cache.json', 'w') as file:\n",
        "        json.dump(self.cache, file)\n",
        "\n",
        "  def __choose_target_set(self, dataset_type: Datasets) -> pd.DataFrame:\n",
        "      return self.training_set if dataset_type == Datasets.TRAINING_SET else self.testing_set\n",
        "\n",
        "  def head(self, dataset_type: Datasets) -> None:\n",
        "    print(self.__choose_target_set(dataset_type).head())\n",
        "  \n",
        "  def shape(self, dataset_type: Datasets) -> tuple:\n",
        "    return self.__choose_target_set(dataset_type).shape\n",
        "\n",
        "  def remove_white_spaces(self):\n",
        "    for target_dataset in self.training_set, self.testing_set:\n",
        "      for i in target_dataset.columns:\n",
        "        if target_dataset[i].dtype == 'object':\n",
        "          try:\n",
        "            target_dataset[i] = target_dataset[i].map(str.strip)\n",
        "          except:\n",
        "            pass\n",
        "\n",
        "  def drop_column(self, column_name: str) -> None:\n",
        "    for set in self.training_set, self.testing_set:\n",
        "      try:\n",
        "        set.drop(self.training_to_testing_map[column_name], axis=1, inplace=True)\n",
        "      except:\n",
        "        set.drop(column_name, axis=1, inplace=True)\n",
        "\n",
        "  def drop_duplicates(self, dataset_type: Datasets) -> None:\n",
        "    self.__choose_target_set(dataset_type).drop_duplicates() \n",
        "  \n",
        "  def get_value_counts(self, dataset_type: Datasets, column_name: str):\n",
        "    print(self.__choose_target_set(dataset_type)[column_name].value_counts())\n",
        "\n",
        "  def replace_null(self, null_place_holder):\n",
        "    for target_set in self.training_set, self.testing_set:\n",
        "      target_set[target_set=='?'] = np.nan\n",
        "\n",
        "  def encoder(self, column_name, encoding_map):\n",
        "    for target_set in self.training_set, self.testing_set:\n",
        "      try:\n",
        "        target_set[column_name] = target_set[column_name].map(encoding_map).astype(int)\n",
        "      except:\n",
        "        target_set[self.training_to_testing_map[column_name]] = target_set[self.training_to_testing_map[column_name]].map(encoding_map).astype(int)\n",
        "\n",
        "  def change_column_value(self,  column_name, from_value, to_value):\n",
        "    for target_set in self.training_set, self.testing_set:\n",
        "      try:\n",
        "        target_set[column_name].replace(from_value, to_value, inplace=True)\n",
        "      except:\n",
        "        target_set[self.training_to_testing_map[column_name]].replace(from_value, to_value, inplace=True)\n",
        "\n",
        "  def change_column_value_not(self, column_name, not_equal_value, equal_value):\n",
        "      for target_set in self.training_set, self.testing_set:\n",
        "        try:\n",
        "          target_set.loc[target_set[column_name] != not_equal_value, column_name] = equal_value\n",
        "        except:\n",
        "          target_set.loc[target_set[self.training_to_testing_map[column_name]] != not_equal_value, column_name] = equal_value\n",
        "\n",
        "  def column_values_with_salary(self, column_name):\n",
        "    print(self.training_set.groupby(column_name)['salary']\\\n",
        "          .value_counts(normalize=True).mul(100).round(1).astype(str) + '%')\n",
        "  \n",
        "  def draw_correlation(self):\n",
        "    corr = self.training_set.corr()\n",
        "    fig, ax = plt.subplots(figsize=(10,10))  \n",
        "    ax = sns.heatmap(corr, \n",
        "                xticklabels=corr.columns.values,\n",
        "                yticklabels=corr.columns.values, annot=True, fmt=\".1%\", linewidths=1.0, square=1)\n",
        "\n",
        "  \n",
        "  def draw_crosstab_with_salary(self, column_name: str, title: str, x_label: str, y_label: str) -> None:\n",
        "    pd.crosstab(self.training_set[column_name], \n",
        "                self.training_set['salary']).plot(kind='bar', figsize=(20,10), stacked=True)\n",
        "    plt.title(title)\n",
        "    plt.xlabel(x_label)\n",
        "    plt.ylabel(y_label)\n",
        "  \n",
        "  def model_test_split(self, test_size):\n",
        "    self.model_x_train = self.training_set.drop(['salary'], axis=1)\n",
        "    self.model_y_train = self.training_set['salary']\n",
        "    return train_test_split(self.model_x_train, self.model_y_train, test_size=test_size)\n",
        "\n",
        "  def machinelearning_model(self, model_name, classification_model, x_train,  x_test, y_train, y_test, **kwargs):\n",
        "    model = classification_model(**kwargs)\n",
        "    model.fit(x_train,y_train)\n",
        "    accuracy = model.score(x_test,y_test)\n",
        "    print(f\"Accuracy of model on testing data: {accuracy}\")\n",
        "    pred = model.predict(x_test)\n",
        "    confusion_matrix(y_test, pred)\n",
        "    kwargs[\"Time Trained\"] = str(datetime.now())\n",
        "    kwargs[\"Accuracy\"] = accuracy\n",
        "    self.__update_cache(model_name, kwargs)\n",
        "    matrix = plot_confusion_matrix(model, x_test, y_test, cmap=plt.cm.Blues)\n",
        "    color = 'blue'\n",
        "    matrix.ax_.set_title('Confusion Matrix', color=color)\n",
        "    plt.xlabel('Predicted Label', color=color)\n",
        "    plt.ylabel('True Label', color=color)\n",
        "    plt.gcf().axes[0].tick_params(colors=color)\n",
        "    plt.gcf().axes[1].tick_params(colors=color)\n",
        "    plt.show()\n",
        "    return model\n",
        "\n",
        "  def prepare_submission(self, model, modelName: str):\n",
        "    pred = pd.DataFrame(model.predict(self.testing_set),columns=[\"salary\"])\n",
        "    pred.index = self.testing_set.index\n",
        "    pred.columns = [\"salary\"]\n",
        "    pred['salary'].replace([0,1],[' <=50K',' >50K'],inplace=True)\n",
        "    pred.index.names = ['index']\n",
        "    pred.to_csv(f\"submission-{modelName}.csv\")"
      ],
      "metadata": {
        "id": "XelM9FvFpKQG"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Pre-processing"
      ],
      "metadata": {
        "id": "utejC9Eit1B-"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "First Step of Pre-processing, let's initialize our model class."
      ],
      "metadata": {
        "id": "knsukB486C9U"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "employeeSalaryModel = ModelPrep()"
      ],
      "metadata": {
        "id": "DsvWKo846Kcn"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Explore Data: "
      ],
      "metadata": {
        "id": "_xULuW0cuUB6"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "First let's take a look at data"
      ],
      "metadata": {
        "id": "qMUkBFIcy7A2"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Getting Overview of Training Data\n",
        "employeeSalaryModel.head(Datasets.TRAINING_SET)"
      ],
      "metadata": {
        "id": "274VRiKxwQf2"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "We can see our columns there and we can see from the first glance there are some columns that need to be cleaned like Captial Gain and Capital Loss, however, this still doesn't give us full overview of the data.\n",
        "\n",
        "We will look into shape to know how many columns and rows we have.\n"
      ],
      "metadata": {
        "id": "KqQn8yym_aCL"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Getting DataSet Size: \n",
        "print(employeeSalaryModel.shape(Datasets.TRAINING_SET))"
      ],
      "metadata": {
        "id": "OiyTlQbcw_rr"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Also, after inspecting we found that there are some trailing spaces in the values, we will start removing those."
      ],
      "metadata": {
        "id": "pNxKVim8FsBl"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "employeeSalaryModel.remove_white_spaces()"
      ],
      "metadata": {
        "id": "Ipah-UxeFruu"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Let's look at the value counts of each column in the dataset!"
      ],
      "metadata": {
        "id": "dfFWnRh8FNuD"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "for column in employeeSalaryModel.training_set.columns:\n",
        "  print(f\"Column: {column}\")\n",
        "  employeeSalaryModel.get_value_counts(Datasets.TRAINING_SET, column)\n",
        "  print(\"\")"
      ],
      "metadata": {
        "id": "dngH517dFTHw"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "We can see that we have several \"?\" in Dataset, let's change it into null.\n",
        "\n",
        "Replace ? to Null and analyze the null values"
      ],
      "metadata": {
        "id": "4b1LVrtV4VNL"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "employeeSalaryModel.replace_null('?')"
      ],
      "metadata": {
        "id": "8IBTOwLN0D57"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Let's analyze how values are in the Dataset"
      ],
      "metadata": {
        "id": "oBIkYlqoQm23"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "employeeSalaryModel.training_set.isnull().sum()"
      ],
      "metadata": {
        "id": "vvakXEa7QmkR"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "employeeSalaryModel.training_set.nunique()"
      ],
      "metadata": {
        "id": "lN6gksvTQ4vD"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Columns Analysis"
      ],
      "metadata": {
        "id": "JKnXDw1Pdscp"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Before we start, let's drop the duplicate rows.\n",
        "employeeSalaryModel.drop_duplicates(Datasets.TRAINING_SET) "
      ],
      "metadata": {
        "id": "VXlVz5EGBLyF"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Age"
      ],
      "metadata": {
        "id": "sOF_p02n8HBw"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "employeeSalaryModel.training_set['age'].plot(kind='kde')"
      ],
      "metadata": {
        "id": "aGfmIhDokcS0"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "The age distribution of our dataset is Positive skewed. (Mean is greater than median)"
      ],
      "metadata": {
        "id": "i2J4ow5Ulwq1"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "sns.FacetGrid(employeeSalaryModel.training_set, hue=\"salary\", height=6, ).map(sns.kdeplot, \"age\", shade=True).add_legend()\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "T5JUGAZ8pMU4"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "As we look more deeper we can see that the age of people who makes <=50k has a left skewed distribution while people who make >50k has a normal distribution."
      ],
      "metadata": {
        "id": "wsLlRImdqTXI"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "employeeSalaryModel.draw_crosstab_with_salary('age', 'Age vs Salary', 'Age', 'Age vs Salary')"
      ],
      "metadata": {
        "id": "pu-Gs3948MG7"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Work-fnl"
      ],
      "metadata": {
        "id": "wGsvwptOu2vz"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Work-fnl has 16k unique values which means it is probably kind of id or something. Therefore, we can safely drop it."
      ],
      "metadata": {
        "id": "OQ-6FDGLu9S9"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "employeeSalaryModel.drop_column('work-fnl')"
      ],
      "metadata": {
        "id": "NeE7ANAeu8OX"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Work class"
      ],
      "metadata": {
        "id": "yT-i0AeawOXb"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Let's analyze the different values of work class columns with salary,and let's not forget that we have null values in it. First, let's assign those null values with unknown for now to be able to analyze them. "
      ],
      "metadata": {
        "id": "8Hrvtc7Oynq-"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "employeeSalaryModel.change_column_value('work-class', np.nan, 'Unkown')"
      ],
      "metadata": {
        "id": "1XIvclFD1b6I"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "employeeSalaryModel.draw_crosstab_with_salary('work-class', 'Work Class vs Salary', 'Work class', 'Work Class vs Salary')"
      ],
      "metadata": {
        "id": "VB-xC0wlynPz"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "We see most of people are in private sectors, and most of people in self-emp earn more than 50%, we can take a better look into values"
      ],
      "metadata": {
        "id": "jxIB8QbY3WiJ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "employeeSalaryModel.column_values_with_salary('work-class')"
      ],
      "metadata": {
        "id": "mIv4lpG54V5U"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "We have here some interesting things. We can see that people without-pay and never-worked will have 100% as less than 50k, so they can be grouped in 1 column. \n",
        "\n",
        "The percentage of money earned in government-related jobs are close to each other, so we can group them as well. \n",
        "\n",
        "44% of People who are  self employed and in company earn more than 50k!  "
      ],
      "metadata": {
        "id": "9r4iAwL8BjJM"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "employeeSalaryModel.change_column_value('work-class', 'Without-pay', 'No pay')\n",
        "employeeSalaryModel.change_column_value('work-class', 'Never-worked', 'No pay')\n",
        "employeeSalaryModel.change_column_value('work-class', 'Federal-gov', 'gov-work')\n",
        "employeeSalaryModel.change_column_value('work-class', 'Local-gov', 'gov-work')\n",
        "employeeSalaryModel.change_column_value('work-class', 'State-gov', 'gov-work')"
      ],
      "metadata": {
        "id": "y8IbSHsoyyHb"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "employeeSalaryModel.column_values_with_salary('work-class')"
      ],
      "metadata": {
        "id": "a36WnTig1y-c"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "employeeSalaryModel.draw_crosstab_with_salary('work-class', 'Work Class vs Salary', 'Work class', 'Work Class vs Salary')"
      ],
      "metadata": {
        "id": "I-yZqEmsSsdI"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "work_map = {'No pay': 0, 'Private': 1, 'Self-emp-inc': 2, 'Self-emp-not-inc': 3, 'Unkown': 4, 'gov-work': 5}\n",
        "employeeSalaryModel.encoder('work-class', work_map)"
      ],
      "metadata": {
        "id": "uPDxAAO92O0c"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Position"
      ],
      "metadata": {
        "id": "v55FDz9mwqjX"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "employeeSalaryModel.change_column_value('position', np.nan, 'Unkown')"
      ],
      "metadata": {
        "id": "txCVSumZrDYw"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "employeeSalaryModel.draw_crosstab_with_salary('position', 'Position vs Salary', 'Position', 'Position vs Salary')"
      ],
      "metadata": {
        "id": "rW3GJx06pjTa"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "employeeSalaryModel.column_values_with_salary('position')"
      ],
      "metadata": {
        "id": "FEOkAXkep9We"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "We have some patterns in jobs, frmo 80% to 100% low paying, from 60 to 80 Medium and the rest are high "
      ],
      "metadata": {
        "id": "hCKbFroGq-io"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "employeeSalaryModel.change_column_value('position', 'Adm-clerical', 'Low Paying Jobs')\n",
        "employeeSalaryModel.change_column_value('position', 'Armed-Forces', 'Low Paying Jobs')\n",
        "employeeSalaryModel.change_column_value('position', 'Unkown', 'Low Paying Jobs')\n",
        "employeeSalaryModel.change_column_value('position', 'Farming-fishing', 'Low Paying Jobs')\n",
        "employeeSalaryModel.change_column_value('position', 'Machine-op-inspct', 'Low Paying Jobs')\n",
        "employeeSalaryModel.change_column_value('position', 'Other-service', 'Low Paying Jobs')\n",
        "employeeSalaryModel.change_column_value('position', 'Priv-house-serv', 'Low Paying Jobs')\n",
        "employeeSalaryModel.change_column_value('position', 'Handlers-cleaners', 'Low Paying Jobs')\n",
        "employeeSalaryModel.change_column_value('position', 'Transport-moving', 'Medium Paying Jobs')\n",
        "employeeSalaryModel.change_column_value('position', 'Sales', 'Medium Paying Jobs')\n",
        "employeeSalaryModel.change_column_value('position', 'Tech-support', 'Medium Paying Jobs')\n",
        "employeeSalaryModel.change_column_value('position', 'Craft-repair', 'Medium Paying Jobs')\n",
        "employeeSalaryModel.change_column_value('position', 'Protective-serv', 'Medium Paying Jobs')\n",
        "employeeSalaryModel.change_column_value('position', 'Exec-managerial', 'High Paying Jobs')\n",
        "employeeSalaryModel.change_column_value('position', 'Prof-specialty', 'High Paying Jobs')"
      ],
      "metadata": {
        "id": "pQuvERZhq-UM"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "employeeSalaryModel.column_values_with_salary('position')"
      ],
      "metadata": {
        "id": "pSXYqe9XyAiM"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "encoder = {'Low Paying Jobs': 0, 'Medium Paying Jobs': 1, 'High Paying Jobs': 2}\n",
        "employeeSalaryModel.encoder('position', encoder)"
      ],
      "metadata": {
        "id": "0Pr-xnoxyYRC"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Marital Status"
      ],
      "metadata": {
        "id": "w9QzuPlMws91"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "employeeSalaryModel.draw_crosstab_with_salary('marital-status', 'Marital Status vs Salary', 'Marital Status', 'Marital Status vs Salary')"
      ],
      "metadata": {
        "id": "2toDR5IPIJPz",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 182
        },
        "outputId": "0d70efb0-aabf-4881-e18a-ad59e5182535"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "error",
          "ename": "NameError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-10-7a9b6c3a86dc>\u001b[0m in \u001b[0;36m<cell line: 1>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0memployeeSalaryModel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdraw_crosstab_with_salary\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'marital-status'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'Marital Status vs Salary'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'Marital Status'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'Marital Status vs Salary'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m: name 'employeeSalaryModel' is not defined"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Interestingly, the married couples have higher percentage of earning over 50k. Let's see that in details"
      ],
      "metadata": {
        "id": "g4zqgQWmN58o"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "employeeSalaryModel.column_values_with_salary('marital-status')"
      ],
      "metadata": {
        "id": "J5X4YR4nN5qa"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "* 90% of both widowed, divorced, and seperated, married spouse absent earn less than 50k, so this cna be grouped in 1 group.\n",
        "* 2 group of married people: Airforces and civilians exist and their percentage is earnings are cose, so we can group them."
      ],
      "metadata": {
        "id": "_4-J2EmOOGEC"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "employeeSalaryModel.change_column_value('marital-status', 'Widowed', 'Unmarried')\n",
        "employeeSalaryModel.change_column_value('marital-status', 'Separated', 'Unmarried')\n",
        "employeeSalaryModel.change_column_value('marital-status', 'Never-married', 'Unmarried')\n",
        "employeeSalaryModel.change_column_value('marital-status', 'Married-spouse-absent', 'Unmarried')\n",
        "employeeSalaryModel.change_column_value('marital-status', 'Divorced', 'Unmarried')\n",
        "employeeSalaryModel.change_column_value('marital-status', 'Married-civ-spouse', 'married')\n",
        "employeeSalaryModel.change_column_value('marital-status', 'Married-AF-spouse', 'married')"
      ],
      "metadata": {
        "id": "aKY5GWCaPQJA"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Let's check the new graph now:"
      ],
      "metadata": {
        "id": "ZEv80QAIP8xY"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "employeeSalaryModel.draw_crosstab_with_salary('marital-status', 'Marital Status vs Salary', 'Marital Status', 'Marital Status vs Salary')"
      ],
      "metadata": {
        "id": "SQA2o4S_QAg7"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "employeeSalaryModel.column_values_with_salary('marital-status')"
      ],
      "metadata": {
        "id": "e3YjQkgPQgA0",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 165
        },
        "outputId": "7993b040-f285-4fb7-b4da-a6e6cf62e428"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "error",
          "ename": "NameError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-11-c5f392b08e65>\u001b[0m in \u001b[0;36m<cell line: 1>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0memployeeSalaryModel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcolumn_values_with_salary\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'marital-status'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m: name 'employeeSalaryModel' is not defined"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "We can see the percentage is slightly the same"
      ],
      "metadata": {
        "id": "AkTjrUEIQfsy"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Let's encode the values!"
      ],
      "metadata": {
        "id": "CtsvkOi3Q_0y"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "married_couple_map = {'Unmarried': 0, 'married': 1}\n",
        "employeeSalaryModel.encoder('marital-status', married_couple_map)"
      ],
      "metadata": {
        "id": "IjPb1AwyRCIJ",
        "outputId": "2d3f8605-8660-470e-e38e-d2feb7c85e66",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 182
        }
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "error",
          "ename": "NameError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-12-27fc738e312e>\u001b[0m in \u001b[0;36m<cell line: 2>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0mmarried_couple_map\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m{\u001b[0m\u001b[0;34m'Unmarried'\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'married'\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0memployeeSalaryModel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mencoder\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'marital-status'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmarried_couple_map\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m: name 'employeeSalaryModel' is not defined"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Relationship"
      ],
      "metadata": {
        "id": "DzZ7tM3JRyZo"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "employeeSalaryModel.draw_crosstab_with_salary('relationship', 'relationship vs Salary', 'relationship', 'relationship vs Salary')"
      ],
      "metadata": {
        "id": "feTLf9uuSu1A"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "* As expected frmo our previous analysis in marital status! Husbands and wives have higher percentage in making over 50%. However, the column own-child is kinda unqiue, because maybe someone has child and divorced. However, we can change Husband and wife to Married!"
      ],
      "metadata": {
        "id": "FrCLY3weTI0R"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "employeeSalaryModel.column_values_with_salary('relationship')"
      ],
      "metadata": {
        "id": "N_y8ftHPT7Et"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "* Interesting enough, we can change own-child, unmarried and other-relative to all unmarried, as their percentages are really close!"
      ],
      "metadata": {
        "id": "QF1IhQE9UMn8"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "employeeSalaryModel.change_column_value('relationship', 'Other-relative', 'Unmarried')\n",
        "employeeSalaryModel.change_column_value('relationship', 'Own-child', 'Unmarried')\n",
        "employeeSalaryModel.change_column_value('relationship', 'Wife', 'Married')\n",
        "employeeSalaryModel.change_column_value('relationship', 'Husband', 'Married')"
      ],
      "metadata": {
        "id": "LcLqU0OFUWlD"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "employeeSalaryModel.draw_crosstab_with_salary('relationship', 'relationship vs Salary', 'relationship', 'relationship vs Salary')"
      ],
      "metadata": {
        "id": "qvgLMpswUyTX"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Let's encode the rest!"
      ],
      "metadata": {
        "id": "gHprESSANkdx"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "relationship_encoder = {'Married': 0, 'Not-in-family': 1, 'Unmarried': 2}\n",
        "employeeSalaryModel.encoder('relationship', relationship_encoder)"
      ],
      "metadata": {
        "id": "A7YzsfDINqXy"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Education & Education Num"
      ],
      "metadata": {
        "id": "ksMZe7qnR7Q1"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "From the analysis, it is obvious that education and education num are the same! Let's drop the education num and do our own encoding of education after analysis!"
      ],
      "metadata": {
        "id": "EI7AyDGlU5iT"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "employeeSalaryModel.drop_column('education-num')"
      ],
      "metadata": {
        "id": "LWyYft5EU5F8"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "employeeSalaryModel.draw_crosstab_with_salary('education', 'Education vs Salary', 'Education', 'Education vs Salary')"
      ],
      "metadata": {
        "id": "h0ta0ZBjR6_p"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "* Of course, we can see that any people still in school will hardly ever have any salary above 50k "
      ],
      "metadata": {
        "id": "GSmzDR98VwZ8"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "employeeSalaryModel.column_values_with_salary('education')"
      ],
      "metadata": {
        "id": "9UBnk-B-V6Hs"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "* Also, Doctorates and prof-school has similar percentages in earning over 50k as well as HS-grad and some college has similar percentage in earning less than 50k."
      ],
      "metadata": {
        "id": "sbA9nDPoWyYW"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "* We can drop those rows with students earning more than 50k and yet in 5th grade -> CAN! \n",
        "\n",
        "* We need to check the age of those education people"
      ],
      "metadata": {
        "id": "Hj6GxccNrj56"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "pd.crosstab(employeeSalaryModel.training_set['education'], \n",
        "            employeeSalaryModel.training_set['age']).plot(kind='bar', figsize=(20,10), stacked=True)\n",
        "plt.title('Age vs Education')\n",
        "plt.xlabel('Education')\n",
        "plt.ylabel('Age')"
      ],
      "metadata": {
        "id": "mdzhig9fHPVo"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "* That's interesting, so we have most of the people in 5th-6th grade are actualy over 25 years old, which means they are school students at best! Therefore, we can start grouping those categories. Also, group associates together. And group HS-grad with Some-college because both of them stopped at HS with similar percentages, and last but not least doctorates with prof-school as they have similar percentages!"
      ],
      "metadata": {
        "id": "jbv3q_g-IP-d"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "employeeSalaryModel.change_column_value('education', '1st-4th', 'School')\n",
        "employeeSalaryModel.change_column_value('education', '5th-6th', 'School')\n",
        "employeeSalaryModel.change_column_value('education', '7th-8th', 'School')\n",
        "employeeSalaryModel.change_column_value('education', '9th', 'School')\n",
        "employeeSalaryModel.change_column_value('education', '10th', 'School')\n",
        "employeeSalaryModel.change_column_value('education', '11th', 'School')\n",
        "employeeSalaryModel.change_column_value('education', '12th', 'School')\n",
        "employeeSalaryModel.change_column_value('education', 'Assoc-acdm', 'Associates')\n",
        "employeeSalaryModel.change_column_value('education', 'Assoc-voc', 'Associates')\n",
        "employeeSalaryModel.change_column_value('education', 'Some-college', 'HS')\n",
        "employeeSalaryModel.change_column_value('education', 'HS-grad', 'HS')\n",
        "employeeSalaryModel.change_column_value('education', 'Prof-school', 'Prof')\n",
        "employeeSalaryModel.change_column_value('education', 'Doctorate', 'Prof')"
      ],
      "metadata": {
        "id": "lvpSMDfNZkUu"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "employeeSalaryModel.column_values_with_salary('education')"
      ],
      "metadata": {
        "id": "zFMbsk4XJHLc"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "We can then start re-encoding the values!"
      ],
      "metadata": {
        "id": "9RdXEJm9LF0c"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "employeeSalaryModel.draw_crosstab_with_salary('education', 'Education vs Salary', 'Education', 'Education vs Salary')"
      ],
      "metadata": {
        "id": "TAuqcN1JdjWN"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "education_encoding = {'Preschool': 0, 'School': 1, 'HS': 2, 'Bachelors': 3, 'Associates': 4, 'Prof': 5, 'Masters': 6}\n",
        "employeeSalaryModel.encoder('education', education_encoding)"
      ],
      "metadata": {
        "id": "TPVWLNB3LXE7"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Native Country"
      ],
      "metadata": {
        "id": "2JptuKvEMdnO"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "From the values we thought in the early beginning, we cna see that US dominates this Dataset! We can see that over 85% of the DS comes from the US. This means, we have a bias in our dataset. We will leave it now and look at the correlation heatmap to determine if we are gonna drop it. \n",
        "\n",
        "However, we see that there are a couple of nulls there! Also, we can see that some countries represent so low in DS! So, we can make all the countries as others and US alone "
      ],
      "metadata": {
        "id": "Zps7OWWdOoa3"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "employeeSalaryModel.change_column_value_not('native-country', 'United-States', 'Others')"
      ],
      "metadata": {
        "id": "8lt1s0uYTqRf"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Let's take a look at data for now!"
      ],
      "metadata": {
        "id": "PSywaF9fVw7T"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "employeeSalaryModel.draw_crosstab_with_salary('native-country', \"Native Country vs Salary\", 'Native Country', 'Native Country vs Salary')"
      ],
      "metadata": {
        "id": "LQYy-RviV0y7"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Encoder\n",
        "country_encoder = {'United-States': 0, 'Others': 1}\n",
        "employeeSalaryModel.encoder('native-country', country_encoder)"
      ],
      "metadata": {
        "id": "hRtOkS8nWcUo"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Gender"
      ],
      "metadata": {
        "id": "AvZaFNa4wwGz"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Let's check the gender, hopefully we will only have TWO genders!"
      ],
      "metadata": {
        "id": "4xK0NTInZ5uK"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "employeeSalaryModel.draw_crosstab_with_salary('sex', 'Gender vs Salary', 'Gender', 'Gender vs Salary')"
      ],
      "metadata": {
        "id": "5fqRQKoqbK0O"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Encoder\n",
        "genders_encoder = {'Male': 0, 'Female': 1}\n",
        "employeeSalaryModel.encoder('sex', genders_encoder)"
      ],
      "metadata": {
        "id": "VDYRWMxybr5T"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Race"
      ],
      "metadata": {
        "id": "KMxLGWJPwykx"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "employeeSalaryModel.draw_crosstab_with_salary('race', 'Race vs Salary', 'Race', 'Race vs Salary')"
      ],
      "metadata": {
        "id": "5qQLgf5Bb_3f"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "employeeSalaryModel.column_values_with_salary('race')"
      ],
      "metadata": {
        "id": "K-kzS-yvcchj"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "employeeSalaryModel.change_column_value('race', 'Amer-Indian-Eskimo', 'Other')"
      ],
      "metadata": {
        "id": "GdFrmQeri44u"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "encoding_map = {'Other': 0, 'White': 1, 'Black': 2, 'Asian-Pac-Islander': 3}\n",
        "employeeSalaryModel.encoder('race', encoding_map)"
      ],
      "metadata": {
        "id": "AkBBOOXljh2y"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Captial Gain"
      ],
      "metadata": {
        "id": "XdRubWyHMiSF"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "employeeSalaryModel.draw_crosstab_with_salary('capital-gain', 'capital-gain vs Salary', 'capital-gain', 'capital-gain vs Salary')"
      ],
      "metadata": {
        "id": "_bkZkbOvYPTg"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.preprocessing import minmax_scale\n",
        "\n",
        "employeeSalaryModel.training_set['capital-gain'] = minmax_scale(employeeSalaryModel.training_set['capital-gain'])\n",
        "employeeSalaryModel.testing_set['capital-gain'] = minmax_scale(employeeSalaryModel.testing_set['capital-gain'])"
      ],
      "metadata": {
        "id": "SX0fOyDE-Mdo"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Capital Loss"
      ],
      "metadata": {
        "id": "TzsrAIY4MlRu"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "employeeSalaryModel.draw_crosstab_with_salary('capital-gain', 'capital-gain vs Salary', 'capital-gain', 'capital-gain vs Salary')"
      ],
      "metadata": {
        "id": "b_NU7k96Ynzi"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "employeeSalaryModel.training_set['capital-loss'] = minmax_scale(employeeSalaryModel.training_set['capital-loss'])\n",
        "employeeSalaryModel.testing_set['capital-loss'] = minmax_scale(employeeSalaryModel.testing_set['capital-loss'])"
      ],
      "metadata": {
        "id": "wo9eFRm8-mVy"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Hours Per Week"
      ],
      "metadata": {
        "id": "-hNXo4xrX6D6"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "employeeSalaryModel.draw_crosstab_with_salary('hours-per-week', 'Hours Per Week vs Salary', 'Hours Per week', 'Hours Per Week vs Salary')"
      ],
      "metadata": {
        "id": "-SOJ74NLh_Np"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "employeeSalaryModel.column_values_with_salary('hours-per-week')"
      ],
      "metadata": {
        "id": "2xwsm-SIiNV2"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Correlation"
      ],
      "metadata": {
        "id": "flrB2vqiyuqH"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "salary_map = {'<=50K': 0, '>50K': 1}\n",
        "employeeSalaryModel.training_set['salary'] = employeeSalaryModel.training_set['salary'].map(salary_map).astype(int)"
      ],
      "metadata": {
        "id": "3OPKIrv7amjN"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "employeeSalaryModel.draw_correlation()"
      ],
      "metadata": {
        "id": "EqvlbugmSxgr"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Correlation Intrepretation:**\n",
        "\n",
        "We can see that Gender and Native-country as well as Race don't contribute "
      ],
      "metadata": {
        "id": "tQnUSZ7CgShP"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "employeeSalaryModel.drop_column('race')\n",
        "employeeSalaryModel.drop_column('native-country')"
      ],
      "metadata": {
        "id": "zaC_TNmVl_OM"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#  Models"
      ],
      "metadata": {
        "id": "37G7z-gvh7Ce"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "x_train, x_test, y_train,  y_test = employeeSalaryModel.model_test_split(0.8)"
      ],
      "metadata": {
        "id": "1kFPvkHVC45N"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Decision Tree: "
      ],
      "metadata": {
        "id": "eY8iDCp3BoqV"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.tree import DecisionTreeClassifier"
      ],
      "metadata": {
        "id": "3PIlhgHS5fsh"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model = employeeSalaryModel.machinelearning_model('Decision Tree with ajsd', DecisionTreeClassifier, x_train, x_test, y_train, y_test, max_depth=7, min_samples_leaf=3)\n"
      ],
      "metadata": {
        "id": "FH9RN1DcYxEY"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.model_selection import GridSearchCV\n",
        "from sklearn.tree import DecisionTreeClassifier\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn import datasets\n",
        "\n",
        "# Create an instance of decision tree classifier\n",
        "#\n",
        "clf = DecisionTreeClassifier(random_state=123)\n",
        "#\n",
        "# Create grid parameters for hyperparameter tuning\n",
        "#\n",
        "params =  {\n",
        "    'min_samples_leaf': [1, 2, 3],\n",
        "    'max_depth': [1, 2, 3]\n",
        "}\n",
        "#\n",
        "# Create gridsearch instance\n",
        "#\n",
        "grid = GridSearchCV(estimator=clf,\n",
        "                    param_grid=params,\n",
        "                    cv=10,\n",
        "                    n_jobs=1,\n",
        "                    verbose=2)\n",
        "#\n",
        "# Fit the model\n",
        "#\n",
        "grid.fit(x_train, y_train)\n",
        "#\n",
        "# Assess the score\n",
        "#\n",
        "grid.best_score_, grid.best_params_"
      ],
      "metadata": {
        "id": "xmE21_J3G2BH"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Random Forest: "
      ],
      "metadata": {
        "id": "vnz96AZJBtfA"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# example of grid searching key hyperparameters for RandomForestClassifier\n",
        "from sklearn.datasets import make_blobs\n",
        "from sklearn.model_selection import RepeatedStratifiedKFold\n",
        "from sklearn.model_selection import GridSearchCV\n",
        "from sklearn.ensemble import RandomForestClassifier\n",
        "# define dataset\n",
        "# define models and parameters\n",
        "model = RandomForestClassifier()\n",
        "n_estimators = [10,1000,10000]\n",
        "max_features = ['sqrt', 'log2']\n",
        "max_depth = [5,12,27,30]\n",
        "# define grid search\n",
        "grid = dict(n_estimators=n_estimators,max_features=max_features)\n",
        "cv = RepeatedStratifiedKFold(n_splits=10, n_repeats=3, random_state=1)\n",
        "grid_search = GridSearchCV(estimator=model, param_grid=grid, n_jobs=-1, cv=cv, scoring='accuracy',error_score=0)\n",
        "grid_result = grid_search.fit(x_train, y_train)\n",
        "# summarize results\n",
        "print(\"Best: %f using %s\" % (grid_result.best_score_, grid_result.best_params_))\n",
        "means = grid_result.cv_results_['mean_test_score']\n",
        "stds = grid_result.cv_results_['std_test_score']\n",
        "params = grid_result.cv_results_['params']\n",
        "for mean, stdev, param in zip(means, stds, params):\n",
        "    print(\"%f (%f) with: %r\" % (mean, stdev, param))"
      ],
      "metadata": {
        "id": "Agc9VWJjwirq"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.ensemble import RandomForestClassifier\n",
        "model = employeeSalaryModel.machinelearning_model('Random Forest', RandomForestClassifier, x_train, x_test, y_train, y_test, n_estimators = 1000, max_features = 'sqrt', max_depth =10, random_state = 10)\n"
      ],
      "metadata": {
        "id": "M2RWstlQqjBn"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "employeeSalaryModel.prepare_submission(model, 'Random Forest')"
      ],
      "metadata": {
        "id": "jkvwNk2HD64u"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### KNN Classifier:"
      ],
      "metadata": {
        "id": "kPk2nKZVBviB"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Logistic Regression: "
      ],
      "metadata": {
        "id": "wjjp0hjyIgvR"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.model_selection import RepeatedStratifiedKFold\n",
        "from sklearn.model_selection import GridSearchCV\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "\n",
        "model = LogisticRegression()\n",
        "solvers = ['newton-cg', 'lbfgs', 'liblinear']\n",
        "penalty = ['l2']\n",
        "c_values = [100, 10, 1.0, 0.1, 0.01]\n",
        "\n",
        "grid = dict(solver=solvers,penalty=penalty,C=c_values)\n",
        "cv = RepeatedStratifiedKFold(n_splits=10, n_repeats=3, random_state=1)\n",
        "grid_search = GridSearchCV(estimator=model, param_grid=grid, n_jobs=-1, cv=cv, scoring='accuracy',error_score=0)\n",
        "grid_result = grid_search.fit(x_train, y_train)\n",
        "# summarize results\n",
        "print(\"Best: %f using %s\" % (grid_result.best_score_, grid_result.best_params_))\n"
      ],
      "metadata": {
        "id": "rXKdh5xFtDLB"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model = employeeSalaryModel.machinelearning_model('Logistic Regression', LogisticRegression, x_train, x_test, y_train, y_test, C=100, penalty='l2', solver='newton-cg')\n"
      ],
      "metadata": {
        "id": "Gwjf-8hHIvDO"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "employeeSalaryModel.prepare_submission(model, 'Logistic Regression')"
      ],
      "metadata": {
        "id": "DlAeqldWJrjC"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# example of grid searching key hyperparametres for KNeighborsClassifier\n",
        "from sklearn.datasets import make_blobs\n",
        "from sklearn.model_selection import RepeatedStratifiedKFold\n",
        "from sklearn.model_selection import GridSearchCV\n",
        "from sklearn.neighbors import KNeighborsClassifier\n",
        "\n",
        "# define models and parameters\n",
        "model = KNeighborsClassifier()\n",
        "n_neighbors = range(1, 21, 2)\n",
        "weights = ['uniform', 'distance']\n",
        "metric = ['euclidean', 'manhattan', 'minkowski']\n",
        "# define grid search\n",
        "grid = dict(n_neighbors=n_neighbors,weights=weights,metric=metric)\n",
        "cv = RepeatedStratifiedKFold(n_splits=10, n_repeats=3, random_state=1)\n",
        "grid_search = GridSearchCV(estimator=model, param_grid=grid, n_jobs=-1, cv=cv, scoring='accuracy',error_score=0)\n",
        "grid_result = grid_search.fit(x_train, y_train)\n",
        "# summarize results\n",
        "print(\"Best: %f using %s\" % (grid_result.best_score_, grid_result.best_params_))\n",
        "means = grid_result.cv_results_['mean_test_score']\n",
        "stds = grid_result.cv_results_['std_test_score']\n",
        "params = grid_result.cv_results_['params']\n",
        "for mean, stdev, param in zip(means, stds, params):\n",
        "    print(\"%f (%f) with: %r\" % (mean, stdev, param))"
      ],
      "metadata": {
        "id": "eEa_GstZvoau"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.ensemble import GradientBoostingClassifier"
      ],
      "metadata": {
        "id": "a_aP5wGBaY3P"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "employeeSalaryModel.prepare_submission(model, 'Decision Tree')"
      ],
      "metadata": {
        "id": "Z0B0LiJLBT1-"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.model_selection import RepeatedStratifiedKFold\n",
        "from sklearn.model_selection import GridSearchCV\n",
        "from sklearn.linear_model import RidgeClassifier\n",
        "# define models and parameters\n",
        "model = RidgeClassifier()\n",
        "alpha = [0.1, 0.2, 0.3, 0.4, 0.5, 0.6, 0.7, 0.8, 0.9, 1.0]\n",
        "# define grid search\n",
        "grid = dict(alpha=alpha)\n",
        "cv = RepeatedStratifiedKFold(n_splits=10, n_repeats=3, random_state=1)\n",
        "grid_search = GridSearchCV(estimator=model, param_grid=grid, n_jobs=-1, cv=cv, scoring='accuracy',error_score=0)\n",
        "grid_result = grid_search.fit(x_train, y_train)\n",
        "# summarize results\n",
        "print(\"Best: %f using %s\" % (grid_result.best_score_, grid_result.best_params_))\n",
        "means = grid_result.cv_results_['mean_test_score']\n",
        "stds = grid_result.cv_results_['std_test_score']\n",
        "params = grid_result.cv_results_['params']\n",
        "for mean, stdev, param in zip(means, stds, params):\n",
        "    print(\"%f (%f) with: %r\" % (mean, stdev, param))"
      ],
      "metadata": {
        "id": "q16iAJywvabe"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# example of grid searching key hyperparametres for SVC\n",
        "from sklearn.datasets import make_blobs\n",
        "from sklearn.model_selection import RepeatedStratifiedKFold\n",
        "from sklearn.model_selection import GridSearchCV\n",
        "from sklearn.svm import SVC\n",
        "# define dataset\n",
        "# define model and parameters\n",
        "model = SVC()\n",
        "kernel = ['poly', 'rbf', 'sigmoid']\n",
        "C = [50, 10, 1.0, 0.1, 0.01]\n",
        "gamma = ['scale']\n",
        "# define grid search\n",
        "grid = dict(kernel=kernel,C=C,gamma=gamma)\n",
        "cv = RepeatedStratifiedKFold(n_splits=10, n_repeats=3, random_state=1)\n",
        "grid_search = GridSearchCV(estimator=model, param_grid=grid, n_jobs=-1, cv=cv, scoring='accuracy',error_score=0)\n",
        "grid_result = grid_search.fit(x_train, y_train)\n",
        "# summarize results\n",
        "print(\"Best: %f using %s\" % (grid_result.best_score_, grid_result.best_params_))\n",
        "means = grid_result.cv_results_['mean_test_score']\n",
        "stds = grid_result.cv_results_['std_test_score']\n",
        "params = grid_result.cv_results_['params']\n",
        "for mean, stdev, param in zip(means, stds, params):\n",
        "    print(\"%f (%f) with: %r\" % (mean, stdev, param))"
      ],
      "metadata": {
        "id": "B3LcmFqZwPK2"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "for mean, stdev, param in zip(means, stds, params):\n",
        "    print(\"%f (%f) with: %r\" % (mean, stdev, param))"
      ],
      "metadata": {
        "id": "iO-8ML9fzBue",
        "outputId": "d31eb92d-b137-4264-cde5-bca0561eedc4",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 182
        }
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "error",
          "ename": "NameError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-13-5f26eef3cfee>\u001b[0m in \u001b[0;36m<cell line: 1>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0;32mfor\u001b[0m \u001b[0mmean\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstdev\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mparam\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mzip\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmeans\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstds\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mparams\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m     \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"%f (%f) with: %r\"\u001b[0m \u001b[0;34m%\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mmean\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstdev\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mparam\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mNameError\u001b[0m: name 'means' is not defined"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# example of grid searching key hyperparameters for RandomForestClassifier\n",
        "from sklearn.datasets import make_blobs\n",
        "from sklearn.model_selection import RepeatedStratifiedKFold\n",
        "from sklearn.model_selection import GridSearchCV\n",
        "from sklearn.ensemble import RandomForestClassifier\n",
        "# define models and parameters\n",
        "model = RandomForestClassifier()\n",
        "n_estimators = [10, 100, 1000]\n",
        "max_features = ['sqrt', 'log2']\n",
        "# define grid search\n",
        "grid = dict(n_estimators=n_estimators,max_features=max_features)\n",
        "cv = RepeatedStratifiedKFold(n_splits=10, n_repeats=3, random_state=1)\n",
        "grid_search = GridSearchCV(estimator=model, param_grid=grid, n_jobs=-1, cv=cv, scoring='accuracy',error_score=0)\n",
        "grid_result = grid_search.fit(x_train, y_train)\n",
        "# summarize results\n",
        "print(\"Best: %f using %s\" % (grid_result.best_score_, grid_result.best_params_))\n",
        "means = grid_result.cv_results_['mean_test_score']\n",
        "stds = grid_result.cv_results_['std_test_score']\n",
        "params = grid_result.cv_results_['params']\n",
        "for mean, stdev, param in zip(means, stds, params):\n",
        "    print(\"%f (%f) with: %r\" % (mean, stdev, param))"
      ],
      "metadata": {
        "id": "Gxaqhl40zODK"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.ensemble import GradientBoostingClassifier"
      ],
      "metadata": {
        "id": "nARYSvbL_o_q"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# example of grid searching key hyperparameters for GradientBoosting Classifier\n",
        "from sklearn.datasets import make_blobs\n",
        "from sklearn.model_selection import RepeatedStratifiedKFold\n",
        "from sklearn.model_selection import GridSearchCV\n",
        "from sklearn.ensemble import GradientBoostingClassifier\n",
        "model = GradientBoostingClassifier()\n",
        "n_estimators = [12,33]\n",
        "max_depth = [4,8,12] #range(1,100)\n",
        "max_features= [2,8,6]#range(1,100)\n",
        "learning_rate=[0.01,0.05,0.1]\n",
        "# define grid search\n",
        "grid = dict(n_estimators=n_estimators,max_features=max_features,learning_rate=learning_rate,max_depth=max_depth)\n",
        "cv = RepeatedStratifiedKFold(n_splits=10, n_repeats=3, random_state=1)\n",
        "grid_search = GridSearchCV(estimator=model, param_grid=grid, n_jobs=-1, cv=cv, scoring='accuracy',error_score=0)\n",
        "grid_result = grid_search.fit(x_train, y_train)\n",
        "# summarize results\n",
        "print(\"Best: %f using %s\" % (grid_result.best_score_, grid_result.best_params_))\n",
        "means = grid_result.cv_results_['mean_test_score']\n",
        "stds = grid_result.cv_results_['std_test_score']\n",
        "params = grid_result.cv_results_['params']\n",
        "for mean, stdev, param in zip(means, stds, params):\n",
        "    print(\"%f (%f) with: %r\" % (mean, stdev, param))"
      ],
      "metadata": {
        "id": "JxH6h2OgVwun"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# example of grid searching key hyperparameters for DecisionTreeClassifier\n",
        "from sklearn.datasets import make_blobs\n",
        "from sklearn.model_selection import RepeatedStratifiedKFold\n",
        "from sklearn.model_selection import GridSearchCV\n",
        "from sklearn.tree import DecisionTreeClassifier\n",
        "# define dataset\n",
        "# define models and parameters\n",
        "model = DecisionTreeClassifier()\n",
        "max_features = range(1,10)\n",
        "max_depth = range(1,100)\n",
        "criterion = ['gini', 'entropy']\n",
        "# define grid search\n",
        "grid = dict(max_depth=max_depth,max_features=max_features,criterion=criterion)\n",
        "cv = RepeatedStratifiedKFold(n_splits=10, n_repeats=3, random_state=1)\n",
        "grid_search = GridSearchCV(estimator=model, param_grid=grid, n_jobs=-1, cv=cv, scoring='accuracy',error_score=0)\n",
        "grid_result = grid_search.fit(x_train, y_train)\n",
        "# summarize results\n",
        "print(\"Best: %f using %s\" % (grid_result.best_score_, grid_result.best_params_))\n",
        "means = grid_result.cv_results_['mean_test_score']\n",
        "stds = grid_result.cv_results_['std_test_score']\n",
        "params = grid_result.cv_results_['params']\n",
        "for mean, stdev, param in zip(means, stds, params):\n",
        "    print(\"%f (%f) with: %r\" % (mean, stdev, param))"
      ],
      "metadata": {
        "id": "lTgDKJmyPF0n"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### XGBoost Classifier:"
      ],
      "metadata": {
        "id": "F6Ghb1ggKh3M"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from xgboost import XGBClassifier\n",
        "from sklearn.model_selection import GridSearchCV\n",
        "\n",
        "estimator = XGBClassifier(\n",
        "    objective= 'binary:logistic',\n",
        "    nthread=4,\n",
        "    seed=42\n",
        ")\n",
        "\n",
        "parameters = {\n",
        "    'max_depth': range (2, 10, 1),\n",
        "    'n_estimators': range(60, 220, 40),\n",
        "    'learning_rate': [0.1, 0.01, 0.05]\n",
        "}\n",
        "\n",
        "grid_search = GridSearchCV(\n",
        "    estimator=estimator,\n",
        "    param_grid=parameters,\n",
        "    scoring = 'roc_auc',\n",
        "    n_jobs = 10,\n",
        "    cv = 10,\n",
        "    verbose=True\n",
        ")\n",
        "\n",
        "\n",
        "grid_search.fit(x_train, y_train)\n",
        "\n",
        "grid_search.best_estimator_\n",
        "\n"
      ],
      "metadata": {
        "id": "8TQM2uTIKkFs"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "grid_search.best_estimator_\n"
      ],
      "metadata": {
        "id": "leDd1u4pMy-i"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model = employeeSalaryModel.machinelearning_model('XGBoost', XGBClassifier, x_train, x_test, y_train, y_test, max_depth=5, n_estimators=40, nthread=4, seed=42)\n"
      ],
      "metadata": {
        "id": "mn40LIViM17l"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "employeeSalaryModel.prepare_submission(model, 'XGboost')"
      ],
      "metadata": {
        "id": "FuKTd7zDNWYV"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}